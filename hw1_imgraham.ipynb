{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = open(\"X_train.txt\",\"r\")\n",
    "\n",
    "def tokenize(string, my_list):\n",
    "    my_list.append(string.split())\n",
    "\n",
    "x_train_tweets = []\n",
    "tokenized_x_train_tweets = []\n",
    "for tweets in x_train:\n",
    "    x_train_tweets.append(tweets)\n",
    "    tokenize(tweets, tokenized_x_train_tweets)\n",
    "    \n",
    "x_train_tokens = []   \n",
    "for tweet in tokenized_x_train_tweets:\n",
    "    for word in tweet:\n",
    "        x_train_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = open(\"y_train.txt\",\"r\")\n",
    "\n",
    "train_tweets_target = []\n",
    "for x in y_train:\n",
    "    train_tweets_target.append(int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making lists of tokenized positive tweets and tokenized negative tweets\n",
    "positive_train_tweets = []\n",
    "negative_train_tweets = []\n",
    "\n",
    "i=0\n",
    "for x in train_tweets_target:\n",
    "    if x == 0:\n",
    "        positive_train_tweets.append(x_train_tweets[i])\n",
    "    else:\n",
    "        negative_train_tweets.append(x_train_tweets[i])\n",
    "    i+=1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_positive_train_tweets = []\n",
    "tokenized_negative_train_tweets = []\n",
    "\n",
    "for x in positive_train_tweets:\n",
    "    tokenize(x, tokenized_positive_train_tweets)\n",
    "    \n",
    "for x in negative_train_tweets:\n",
    "    tokenize(x, tokenized_negative_train_tweets)\n",
    "    \n",
    "positive_train_tokens = []   \n",
    "for tweet in tokenized_positive_train_tweets:\n",
    "    for word in tweet:\n",
    "        positive_train_tokens.append(word)\n",
    "        \n",
    "negative_train_tokens = []   \n",
    "for tweet in tokenized_negative_train_tweets:\n",
    "    for word in tweet:\n",
    "        negative_train_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the counts of the words from our token lists\n",
    "count = Counter(x_train_tokens)\n",
    "count_positive = Counter(positive_train_tokens)\n",
    "count_negative = Counter(negative_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129853/129853 [00:00<00:00, 539982.90it/s]\n"
     ]
    }
   ],
   "source": [
    "keys1 = list(set(x_train_tokens))\n",
    "len_train_tokens = len(x_train_tokens)\n",
    "len_targets = len(train_tweets_target)\n",
    "\n",
    "def train(smoothing_alpha=0):\n",
    "    global prob_x_dict1\n",
    "    global prob_pos_tweet\n",
    "    global prob_neg_tweet\n",
    "    global prob_x_given_positive_dict\n",
    "    global prob_x_given_negative_dict\n",
    "  \n",
    "    values1 = []\n",
    "    for word in keys1:\n",
    "        values1.append(count[word]/len_train_tokens)\n",
    "    prob_x_dict1 = dict(zip(keys1, values1))\n",
    "     \n",
    "    prob_pos_tweet = train_tweets_target.count(0)/len_targets\n",
    "    prob_neg_tweet = train_tweets_target.count(1)/len_targets\n",
    "    \n",
    "    positive_values = []\n",
    "    negative_values = []\n",
    "    \n",
    "    pos_count = len(count_positive)\n",
    "    neg_count = len(count_negative)\n",
    "    len_set = len(set(x_train_tokens))\n",
    "     \n",
    "    with tqdm(total=len_train_tokens) as pbar:\n",
    "        for word in x_train_tokens:\n",
    "            positive_values.append((count_positive[word]+smoothing_alpha)/(len(count_positive)+len_set*smoothing_alpha))\n",
    "            negative_values.append((count_negative[word]+smoothing_alpha)/(len(count_negative)+len_set*smoothing_alpha))\n",
    "            pbar.update(1)\n",
    "            \n",
    "        prob_x_given_positive_dict = dict(zip(x_train_tokens, positive_values))\n",
    "        prob_x_given_negative_dict = dict(zip(x_train_tokens, negative_values))\n",
    "                  \n",
    "train(smoothing_alpha=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "def classify(tweet):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    \n",
    "    for word in tweet:\n",
    "        if word in prob_x_given_positive_dict:\n",
    "            positive.append(prob_x_given_positive_dict[word])\n",
    "        if word in prob_x_given_negative_dict:\n",
    "            negative.append(prob_x_given_negative_dict[word])\n",
    "            \n",
    "    pos = []\n",
    "    neg = []\n",
    "    \n",
    "    for x in positive:\n",
    "        if x != 0:\n",
    "            pos.append(math.log(x))\n",
    "    for x in negative:\n",
    "        if x != 0:\n",
    "            neg.append(math.log(x))\n",
    "            \n",
    "    pos_post = math.log(prob_pos_tweet) + np.sum(pos)  \n",
    "    neg_post = math.log(prob_neg_tweet) + np.sum(neg) \n",
    "    \n",
    "    if pos_post > neg_post:\n",
    "        classification.append(0)\n",
    "    else:\n",
    "        classification.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = open(\"X_dev.txt\",\"r\")\n",
    "\n",
    "x_dev_tweets = []\n",
    "tokenized_x_dev_tweets = []\n",
    "for tweets in x_dev:\n",
    "    x_dev_tweets.append(tweets)\n",
    "    tokenize(tweets, tokenized_x_dev_tweets)\n",
    "    \n",
    "y_dev = open(\"y_dev.txt\",\"r\")\n",
    "\n",
    "dev_tweets_target = []\n",
    "for x in y_dev:\n",
    "    dev_tweets_target.append(int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tokenized_x_dev_tweets:\n",
    "    classify(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7164804469273742\n"
     ]
    }
   ],
   "source": [
    "x = f1_score(dev_tweets_target, classification, average='binary')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.22428748451053285 with regular tokenize and alpha = 0\n",
    "# 0.7164804469273742 with regular tokenize and alpha = 1\n",
    "# 0.682437275985663 with regular tokenize and alpha = 2\n",
    "# 0.6627651792245794 with regular tokenize and alpha = 3\n",
    "# 0.6494082840236686 with regular tokenize and alpha = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1,2,3,4], [0.22428748451053285, 0.7164804469273742, 0.682437275985663, 0.6627651792245794, 0.6494082840236686])\n",
    "plt.axis([0, 4, 0, 1])\n",
    "plt.xlabel('Smoothing Value')\n",
    "plt.ylabel('Performance')\n",
    "plt.xticks([0, 1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = open(\"X_train.txt\",\"r\")\n",
    "\n",
    "def better_tokenize(string, my_list):\n",
    "    my_list.append(string.lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"'\", \"\").replace(\"-\", \" \").replace(\"_\", \" \").split())\n",
    "#     my_list.append(string.lower()\n",
    "x_train_tweets = []\n",
    "tokenized_x_train_tweets = []\n",
    "for tweets in x_train:\n",
    "    x_train_tweets.append(tweets)\n",
    "    better_tokenize(tweets, tokenized_x_train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129853/129853 [00:00<00:00, 579897.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train(smoothing_alpha=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = open(\"X_dev.txt\",\"r\")\n",
    "\n",
    "x_dev_tweets = []\n",
    "tokenized_x_dev_tweets = []\n",
    "for tweets in x_dev:\n",
    "    x_dev_tweets.append(tweets)\n",
    "    better_tokenize(tweets, tokenized_x_dev_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "for tweet in tokenized_x_dev_tweets:\n",
    "    classify(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5121527777777778\n"
     ]
    }
   ],
   "source": [
    "x = f1_score(dev_tweets_target, classification, average='binary')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2766749379652606 with better tokenize and alpha = 0 - just lower\n",
    "# 0.6581132075471698 with better tokenize and alpha = 1 - just lower\n",
    "# 0.6118935837245697 with better tokenize and alpha = 2 - just lower\n",
    "\n",
    "# 0.3185947910357359 with better tokenize and alpha = 0\n",
    "# 0.5486577181208053 with better tokenize and alpha = 1\n",
    "# 0.5121527777777778 with better tokenize and alpha = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = open(\"X_test.txt\",\"r\")\n",
    "\n",
    "x_test_tweets = []\n",
    "tokenized_x_test_tweets = []\n",
    "for tweets in x_test:\n",
    "    x_test_tweets.append(tweets)\n",
    "    better_tokenize(tweets, tokenized_x_test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "for tweet in tokenized_x_test_tweets:\n",
    "    classify(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Id', 'Category'])\n",
    "\n",
    "ids = []\n",
    "i = 0\n",
    "for x in classification:\n",
    "    ids.append(i)\n",
    "    i+=1\n",
    "    \n",
    "df['Id'] = ids\n",
    "df['Category'] = classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/img/Desktop/630/Week2/hw1/outputs-NB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = []\n",
    "for x in x_train_tokens:\n",
    "    if x not in unique_tokens:\n",
    "        unique_tokens.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0, index=range(len(tokenized_x_train_tweets)), columns = unique_tokens)\n",
    "df\n",
    "\n",
    "i = 0\n",
    "for tweet in tokenized_x_train_tweets:\n",
    "    for word in tweet:\n",
    "        if word in unique_tokens:\n",
    "            df.at[i,word] = df.at[i,word] + 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sparse = df.as_matrix()\n",
    "\n",
    "intercept = np.ones((sparse.shape[0], 1))\n",
    "sparse = np.hstack((sparse, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(input_vector, beta_vector):\n",
    "    yhat = 1/(1 + math.e**-(np.dot(beta_vector, input_vector)))\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_liklihood(target, betas, matrix_x):\n",
    "    b_times_x = np.dot(betas, matrix_x)\n",
    "    ll = target*b_times_x - np.log(1 + math.e**(b_times_x))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(phat, vector_x, target, learning_rate, betas):\n",
    "    deriv = (phat-target)*vector_x\n",
    "    outcome = betas - (learning_rate*deriv)\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "def predict(matrix_x, betas):\n",
    "    i=0\n",
    "    for x in matrix_x:\n",
    "        phat = sigmoid(x, betas)\n",
    "        predictions.append(phat)\n",
    "    for x in predictions:\n",
    "        if x>=0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression(matrix_x, targets_vector, learning_rate, num_step):\n",
    "    \n",
    "    global betas\n",
    "    betas = np.asarray([0]*len(matrix_x[0]))\n",
    "    learning_rate = learning_rate\n",
    "    num_step = num_step\n",
    "    rands = list(range(0, 10000))\n",
    "    \n",
    "    graph_x = []\n",
    "    graph_ll = []\n",
    "    \n",
    "    i=1\n",
    "    for index in range(num_step):\n",
    "        rand = random.choice(rands)\n",
    "        vector = matrix_x[rand]\n",
    "        ground_truth_class = targets_vector[rand]\n",
    "        \n",
    "        phat = sigmoid(vector, betas) \n",
    "#         print(phat)\n",
    "   \n",
    "        ll = log_liklihood(ground_truth_class, betas, vector)\n",
    "        \n",
    "        graph_x.append(i)\n",
    "        graph_ll.append(ll)\n",
    "        i+=1\n",
    "#         print(ll)\n",
    "        \n",
    "        outcome = compute_gradient(phat, vector, ground_truth_class, learning_rate, betas)\n",
    "        betas = outcome\n",
    "#         print(outcome)\n",
    "\n",
    "    global graph_x1\n",
    "    global graph_x2\n",
    "    global graph_x3\n",
    "    graph_x = np.asarray(graph_x)\n",
    "    graph_x1 = np.mean(graph_x.reshape(-1, 100), axis=1)\n",
    "    \n",
    "    global graph_ll1\n",
    "    global graph_ll2\n",
    "    global graph_ll3\n",
    "    graph_ll = np.asarray(graph_ll)\n",
    "    graph_ll1 = np.mean(graph_ll.reshape(-1, 100), axis=1)\n",
    "#     print(graph_ll1)\n",
    "\n",
    "#     plt.plot(graph_x1, graph_ll1)\n",
    "#     plt.show()\n",
    "\n",
    "# logistic_regression(sparse, train_tweets_target, 5e-5, 1000)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression(sparse, train_tweets_target, .05, 3000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd7wV1b338c+PrqBIB1sIERIRvQhHrtgLoOaqGKPRqBF99EWu3mtiioohPrlPohG7McUrtqDRGEsMqDcqoMYULIegYkPQeG0EDvYekd/zx5qdXc7us/fZ7ft+veY1bc2sNYfN/GbWrFlj7o6IiLS2brUugIiI1J6CgYiIKBiIiIiCgYiIoGAgIiJAj1oXIJfBgwf7yJEja10MEZGGsnTp0nXuPqTU7eo2GIwcOZL29vZaF0NEpKGY2f+Ws11FqonMbH8zW2Fmq8xsVpb1vc3sN9H6h81sZCXyFRGRyogdDMysO/Bz4ABgLPBVMxubkewE4E133wa4BDgvbr4iIlI5lbgzmASscvcX3P0fwE3A9Iw004F50fStwL5mZhXIW0REKqASwWAL4OWU+VeiZVnTuPt64G1gUOaOzGymmbWbWXtHR0cFiiYiIsWoRDDIdoWf2eFRMWlw97nu3ububUOGlPwwXEREylSJYPAKsFXK/JbAa7nSmFkPoD/wRgXyFhGRCqhEMHgUGG1mnzWzXsCRwIKMNAuAGdH0YcB9ru5SRUTqRuxgED0D+E/gHuAZ4GZ3f8rMfmhmB0fJrgYGmdkq4NtAp+anIlKn3MMgpXnnHXjyyfRlb78Nv/51cr6O/rYVec/A3f/H3ce4++fc/Zxo2f919wXR9Efufri7b+Puk9z9hUrkKyJdoFs3GD0a1q8P86++CitWVG7/r78OH34Iq1bBPfeEk+ODD8K118I//hHyvfxyOP10WLkSTjwRPv009/4++igMAIsWwQMP5M9/1ixIbdx45plwww1h+lvfguuug46OUK4XXoDnnoM1a2DDBnjpJfjgA7j33uT2r7wS9te/P2y/fZg2gzvugM02g6OOCvO33Rb+tsOGwbJlYdkjj5T1J6wId6/LYeLEiS7S8j76yP2999KXnXqq+zHHuK9bV9m8NmwI+bm7f/KJ+8cfh+nE9evs2e4ffJCcv/XWMGzYENLddVdyHbg/8oj7+vXuzz7r/vTTyXwuvzysv/tu9x//OEzvuGP6trmGiROT+3Z3f+gh9wULkuvvuMO9b1/37t3dH3yw8/ZXXRXGN9zQed1PfuJ+2GHJ+RtvLK5MqcPRR7sfdFDp22UOO+1U9j8j0O5lnHNrftLPNSgYSF27+mr3adOqt/9XXw3jUaPCf9PTTnM/6aSwLHHCmDzZffFi9//6L/fzznPfYotk4Pj0U/c333Q/+2z39nb3554L29x0k/vate7f/777WWeFk3lif1//ehi//HJy2dSphU9cs2e7r17tvtdendfts0/6/CmnxD9RtspQJgUDkXKtW+d+4YXJK9xrrw1XmAkffuj+v/+bnF+xIvkf9gc/yL7Phx5y79/fvaMjXM2ec05Y/tZb4WTsHq6Yn3jC/e9/T+5v7lz3P/4x9wli773jn2QSV9ca6nsoU7nBwMK29aetrc3VUV2Tcw8P2fr3r/y+r7sOJk8O9bBbbAEbbdQ5zVtvwYABufexYUOorz7iCLj99jDdvXt6/TLA4YfDLbeE6QsvhO9+N/v+/vAH2HPPML1uHQweXPpxSeso89xsZkvdva3U7fQ9A+l6n3wSgsB554UHaq9lvpZSpDvuCCfmjg54881w8l65Ev7zP2HGDBgzJjz43HjjkO7HP4a//x1+9KMwf9JJ+fd/7rnQq1cIBAA9enQOBJAMBJA7EEAyEIACgdSfcm4numJQNVGTeO019yuvTM6vXu2+/faeVl2xaJH7K68k06xb577VVu6PPea+224hzXvvud92m/uyZe4nn+z+zjvuEybU/lZeg4ZqDWWizGqiuv2egdSYO1x6aagi2Xzz7GlGjID99oNf/jLMr18fqkK22w6GDw/Lpk+HRx+FTTYJy7ffPj0PgClT0ufvuQdefhnGj0+m7dcvPe9f/CLW4YlIhnIiSFcMujOoofffDw83wX277cKy3/0uPOxMSKwH94MPTr+i2XrrkCZb8718w2c/G7abNKn2V2UaNNR6KBNl3hnomUGrWL8eLr44vMSTsGEDfP/74QUaCHXvxx4LffvCF74Qlj31VHjYecghsMMOYdm11ybXAyzI6H3kpZfguOPg6KNLK+Pf/gZr19b2xRuRFqXWRM3qjTdCS5nEA8+f/zw8WO3WLQSBDz6AJUtg333hwAOTD2MLGTgw7FtEqqvMc7NaE0nS88/DoEHw05+GO4Jbb4X33gvrNmwI4403DoEA4M47Q6ubYigQiDQlPUBuJB9+GE7048aF+SVLwsPZmTPhrrtg+fLQl0qin5Q77wxBYPbswvtetap65RaRuqdgUO+eeSYEgQkTQn3+rbeGl6XOPTe00wf4y1/gN78J01dcEdrSQ7jNLCYQiEjLUzCotQ8/DFU2xx8P11zTef3YsWF80UXJ3hcnTAi9JyYkAgEkAwGEHhtFRIqgYFBrq1eH8bXXwqhRsNdesNtuIUiccEIy3Xe+k5x+QT2Ai0hlKRhUw+uvh24MNtmkcNrUuvqzzqpemURE8lBromoYPBhGjsy9/qabQsdpK1aEN3hFRGosVjAws4FmttDMVkbjrF1AmtndZvaWmd0ZJ7+Gkq0J5quvwp/+BKedFr7ElPrilohIDcW9M5gFLHb30cBicn/b+ALgazHzanyjRsHuu4fP4omI1JG4wWA6MC+angccki2Ruy8G3o2ZV2NIfWvw00/h/ffDi15HHJHeFYSISB2J+wB5mLuvBnD31WY2tAJlalzLlqWf8MeODR/PFhGpcwWDgZktAoZnWVXxt5nMbCYwE2Drrbeu9O4ra8OGMPSI/oR//nNoEnroock0CgQi0iAKBgN3n5JrnZmtMbMR0V3BCGBtnMK4+1xgLoSO6uLsq+q++MXQ7747LFwYPncIya4gREQaSNxqogXADGBONJ4fu0SN4p57wvjhh2HatOTyRIdwIiINJO4D5DnAVDNbCUyN5jGzNjO7KpHIzP4I3ALsa2avmFnzNK7feedal0BEJLZYdwbu/jqwb5bl7cCJKfO7x8lHRESqS28gi4jUm8MO6/IsFQzKob7/RaSaLrmky7NUMCjGhg3wySfhJTKz4r8KJiJd6/DDa12Cythyyy7PUsGgGEcdFXoh3X//WpdEpPFV87vrA7J2jyZFUDAoRuLjMfpYjEh9q2agaXIKBvmccQZstlmtSyFSPQ8/XOsSVJaCQdkUDPI5/3x4++1al0KkeiZNqm3+BxxQ2/wrqcGPRcEgYdNN4ac/Tc6ffnrtyiLSlX75y9rlvdNOld1fLe8MunfPvvzpp7u2HGVSMEh49134xjeS8xdcULuyiFRK377w5pv504wY0TVlyeZf/7W87RIXbpkn4HqrJtp0U9h221qXoigKBpnuvBNOPrnWpRBJ169fedv17l34uVfv3uXtuxJS+/UqxVZbhXGuq/FirFxZXLpiLwzNOi/bddfC2+2xR/p8uf/WMSkYZDroILj88lqXQiRdz561LkFlzJmTPt+jyB5xfvzj5PQPf5g7iJRyZ1Bs3httVPw+y3HNNenz79bmO2AKBiL17uyzu/4lpBkzytuu0Ml4eLZPoxShb9/k9FlnQbccp65ig8EZZ8DIkeWVJZdsdwbZlmX63OcqW44yKRhA/dUzSuPoim4Djjoqfb5Xr+K3LeZklGqTTUL37ImqitQ3elesKG1flZQ4ju22y5+u2P/LJ5wQrzzFKvXvX+kAVQIFA5FyjRvXNVd1ZuVfsOS6gk6Vuu9nnw1VMNlOYmPGZN/+mWdy7/v992GbbQqXoZCePcO+/vrX0rar9BvJiTu0bH+LYu8Mrr029/6XLi2vXBXQ2sFgzpzwj/Xpp7UuiTSa3/8eliyp3l3l4sXJ6cwTSupD01LuEoqx+eZhnDiuRDDZZZfc23zhC7nXbbxx+DsVo1BV2MYbJ4838TfJ/Ptnzn/pS9n3VcoV+7HHhvHAgSHwdXQUvkv6yU9y53Pccbm3Gziw+HJVWGsHgzPPDON162pbDilfMVe+1bDFFqEqpVofN9pnn/T51JPxGWckp7MFo5//vLS88p0Yc510SzF4cPLLgPmCSil5FBsMSpWtqWui6uyZZ8K/+eDB+csE8JnPdF5W51o7GCTUsp21NKYhQ8J46FB49dXq5mUW2tWPGhXmN9kkd9pzz4WZMyuTZ+o47kl22rSwj3w9/u64Y/r8FVfAMceUlk9mOc1C68BCdx3/8i9hnGiymvDSS2E8bVr4t071l7+kz6de8SfKkfj7VbtFUgW0bjD44INal0Dq0ahRMGVK/jQHH5y7VYw7PPpoZcqSOIGZheqR7bcP86nt0DN70j311PQmk+VemSbeDB43Low3bEhfX8wdUaKDx0IS9e/nnpu+fObMUDUE8a6w//3f4eWX05dl7u/WW8PfLrV7jkmTOgeHVJMnJ6fdYfr09PnUfDLz/+ST4srehWIFAzMbaGYLzWxlNO70tMbMxpvZEjN7ysyeMLMj4uRZMRMn1roEze2668rf9mtfKy39/Plwxx3l55dqxQpYuBAuvjh3msRdQaZEgGhrSy4r9Yo69YXHW26BQw5J1uMnDB0Kf/oTLF8OV12Vvi7zSjRxMi/V174WPuK0b6ev2gZLlsC994YHzrl85Sul5dmzZzIIFdtNRaWqibbZJrQM+8Y3wnsMH35YXid+iYCQWY5Bg9Lne/RID+rXXgvXX196fhUU985gFrDY3UcDi6P5TB8Ax7r7dsD+wKVmVvuuQPP9iCW+/v3hxhvL2zazGuSNN/KnP/hgOPDA5Hy5D1XvvTd5VV3KlWgpaXN1TfDlL8ORR4b6/sSJZOed4fbbkw+MU08wu+4aTvSpx3ryycn5/fYL4//4j/R8iv2colloKZWvmmjqVPj854vbX7ZtE7+PxHMf92QQKPSeQ66/eb5gcN994e/ymc/krjbq3Tu8x9CnT/78E267Ldx5JPz2t/Dxx53vDLJZvhwWLAjTxx1XepVYhcUNBtOBedH0POCQzATu/py7r4ymXwPWAjkuraRpmMFXv1qZfZX69u3pp4dglOm55/JvN3Vqcjrff+JcJ5xcy1evzp/v974HN98Mv/51/nT5yta/fwgkmesy52+5JbSEKlZi+8xqorjuvTf5+5g/H775zfTAUu4Vfr7t9t4b7r4bXnyxcl1wHHpoeo8F3bqFgJwtGNx2G5xySnJ+5MjQ40GdiBsMhrn7aoBoPDRfYjObBPQCns+xfqaZtZtZe0dHR8yiSU3tsEMYX3hh6dtmnsD69YNf/aq07bPdcpfyudJSmvgVujNIfb6QLe1BB5XfKqqck2bmc4Z8x1qpB8j5jBkDl17aUC1vipZ6TIceCpddVruyFFDwF2hmi8zsySzD9ELbZuxnBHA9cLy7Z73McPe57t7m7m1DctXLVsKaNdXbdytJrZrJtPXWlc3r6KNLS3/QQfG6Ic+W3ze/Gcal3hmkinPCS/y9s1XNFNrv976Xe13iwXQ2XREMqplvrQJM4mIo13sOdahgMHD3Ke4+LsswH1gTneQTJ/u12fZhZpsCdwHfd/eHKnkAZSm3fxRJl6jvTEhtepf4T3jccbD77sXtL99D21Ik8v7618v/Ul22K/XEf/Bc+RVz4vrOd3JvX8iJJ8Jbb6W/5NW/P+y1F9x0U/5tzzmnvBNrojql1t8WzvwbJf59Ult+tbXBD37QdWXKZ8yY8Oyg1IuYGopbTbQASDzpmQHMz0xgZr2A24Hr3P2WmPlJPSnmJDZoEDz4YP40d90VmvYV24vkDTdkX37SSenlGjWqc1/+N9+cfdsJEzovO+00uOii5HzifZREe/+EbMEg1wXH8ceXf7Vr1vlZSLducP/9yQfG5Xr00ezBeLvtQtVGsc8z4ko8RE19fpNNt26h5ddvf5tc9uij5T/QroZKvx1eZXGDwRxgqpmtBKZG85hZm5kl2rx9BdgDOM7MHouG8THzla5UbBPBck9yX/xiaE2TUCjI5FqfqFrMt322ViJ/+lNoTprp/PPh299Ozh9wQHgAmXhzPV95XngB3nknOX/nnfDUU8n5U05JthKqxfcEXn45ve17Wxt861ud05mFsma+cFUtkyeH31GufpBSjRmTfA8h1c03w/e/X/myNblYwcDdX3f3fd19dDR+I1re7u4nRtO/cvee7j4+ZXisEoWXLpJ6633MMeEKLHFCXL++cF16Nod0aniWLl9V3ujR4eSaqZj8sz0s3XXX4h8Y77df7g+qpOa/0UbpTWT/7d9g7Njk/GWXwdq1oSXK+CpcGyW6TMh2soTQtLKS3WIvWwaPP165/cVx+OHJ7iCkaEXel0vTGTo0nIzK0daWfLGqe/dw9fzgg7DnnqFVyKxsr5tkuP32zlfUqSfT5cvhoRyPl9rasncuWEzb7mK+PFWqch9SDhyY3ka9ki65JHTvUO6XxHLZdNPsV93VCGhxHHMMPPJI+kdxJK/W645i0aJal6A+/OhHudeVegLZeuvQtXC+FmDPPlv8394sXNkeeGDuFkvduoWmeqlt5osJBpDc56GHhhNGpdTTdzH69QsvoVW6Nc3bb4dnKV3lhz+EI44o/UFsnz4wd27uTuUS9t+/ep0NNpjWuzMo9GCqmdxwQ+7/RPna3O+xR3gpKJtym09+/vOVfbhnFl7iSVVsMEg8NzjhhOK7PShUFqmO4cMLt5SKo5QX8Jpca90ZZH5rtFEcf3x522V+ISvV3nuHet5iXrvvqiveQvksWVJc08HMk/P114cHvwmXXx6eecRtgSP14cYb4YEHal2Khtc6dwYPPth1n7qrB8WcNMePz96evtyTf+LKP/VBaTlyXWnvvHP+W/ovfznUEWe+4p/Z58vgwdWpS66naqJWUqluT1pc6wSDPfesdQm6VuLFpJ4983eXe+SRlbtj+vKXob09e5v9hFWrQrPLapgwoTon5DfeyP83VDWRNIHWqiZqRn/+c3hpK5f29vD2aWZ/6glXXNF5WeYJNbWNeaGT7cSJ+U+On/tc7uc29XplPWBA/nb2m24aXpi74IKuK5NIhSkY1LNiOlbbZZfw0lamxIl1hx3y90uT+tbvtGnZP8wyZEhoMloN2frbb7Qr7R49wp1DK1VDStNpjWqiRv12QSVPisXsK/Gd2tSHrQmFmuiV4+OPa/cNYxFJ0xr/E/faq9YlaCynnho6Rau2Xr3S70zqtZpIpAW0RjBo1C6r45wc42zbrx9ceWX528fVaNVEIk2gNYJBo6vEyTHuPoYNC+PMHjtFpCm0xjODRjB6NKxcmX1dOVf5mdvk6rAsoVAvkVOmhFZLle7rJlXiYfLEidXLQ0Syav5g8P77tS5BfrfdFtrnm4WujD/+OLmuknXom20GS5eGE21ml8nLlhX3ZbJsrZYqaerUEBC32aa6+Uh1/eIX8MQTtS6FlKj5g0G/frUuQdKmm6b3cQ/Fva1bThVPtkAyYUL4EEpmVU899TipQND4Eh8ZkobS/MGgnuRrRpnthF+N1jVqWSUiWegBcqWV2l9+vp42Ex/oKKWvH9W3i0gZFAwqLfVkvOOO6evM4LvfTV+WGgwy7wSmTIG//CX75whzmTMnjHfZpfhtcjnnHLjjjvj7EZG6FysYmNlAM1toZiuj8YAsaT5jZkujbx8/ZWZV+rRTF+vePf1bAYnO2VJP6Pfd13m7Cy5IT5OtKijxJanPfz58EzZb9dLEibDbbp2XT5kS9lmJJqDf+17uj8uISFOJ+8xgFrDY3eeY2axo/oyMNKuBXdz9YzPrBzxpZgvc/bWYeddWZrVO376d02y2Wfp8vm8HpO5v9mz40pey9/755JPhgx+DBhVfVhGRAuJWE00H5kXT84BOXzl393+4e6K9ZO8K5FkfevfOflWf76Hv/fcXl94sdzfQ222nQCAiFRf3xDzM3VcDROOs/fya2VZm9gTwMnBerrsCM5tpZu1m1t7R0RGzaFWW62Pt+YJBvs8+msH06WG6e/fyyqQqHREpU8FqIjNbBAzPsmp2sZm4+8vADma2OfA7M7vV3Tt1GOTuc4G5AG1tbfHbVf7tb7F3kdO4cZVp+pm6j+uvh4svTu+8rVjr16sHUBEpW8GzjrtPybXOzNaY2Qh3X21mI4C1Bfb1mpk9BewO3FpyaUt19tnV3X/qiTxR5z9kSPq4WIk3kLfcMvv6zLeTM5V7NyEiQvxqogXAjGh6BjA/M4GZbWlmG0XTA4BdgRUx8y3OLbd0STZpEkFh222LS1/s3cXzz8PDD5dXJhGRAuIGgznAVDNbCUyN5jGzNjO7KkqzLfCwmT0O/AG40N2Xx8y3OO++W539Jvr2qeQbwoWqeLbYAiZNqlx+IiIpYjUtdffXgX2zLG8HToymFwI7xMmn7uTrhGunnaCtDS66qLh9jRsHp5wC3/hGZcomIlKG5u2baOnS6u070d1z6p3BiBFhPHhw9u8I59KtG1x2WeXKJiJShuYNBq++Wv08UoPB3Lmw//7hzkBEpME0b1vErvye7uGHh+6pjzuu6/IUEamg5g0GZ51V/TwSAeewwwqnVUsgEaljzVtNtLxrGiwBxX18JrMl0JVXhrsJEZE60LzBoCtccgn06gUHHVT6tieeWPnyiIiUScEgji23hBtuqHUpRERia95nBiIiUjQFAxERUTAQEREFAxERQcFARERQMBARERQMSjNsWK1LICJSFQoGpbj7blib92NuIiINScEg1c4751/fp0/pn7MUEWkACgaplixJnx88OH2+mD6IREQaUKxgYGYDzWyhma2MxgPypN3UzF41s5/FybNLdWU32CIiNRT3zmAWsNjdRwOLo/lcfkT4BrKIiNSZuMFgOjAvmp4HHJItkZlNBIYB98bMr7LGj++87Mkn4frrw3TqnUGvXrDVVl1TLhGRLhY3GAxz99UA0XhoZgIz6wZcBJxWaGdmNtPM2s2svaOjI2bRinDwwdDRAXvskVy23XZwwAHp6SZNgo8/ho03rn6ZRERqoGAX1ma2CBieZdXsIvM4Gfgfd3/ZCjyAdfe5wFyAtra2rqmwHzwY7r8f1q/PViBYtw769u2SooiI1ErBYODuU3KtM7M1ZjbC3Veb2QggWyP8ycDuZnYy0A/oZWbvuXu+5wtdq1u3UA2UkBq0Bg3q+vKIiHSxuB+3WQDMAOZE4/mZCdz96MS0mR0HtNVVIMgmEQzUmkhEWkTcZwZzgKlmthKYGs1jZm1mdlXcwpXtjTfibb/ZZvCd78ADD1SkOCIi9S7WnYG7vw7sm2V5O9DpI7/u/kvgl3HyLMqGDfnXH3UU3Hhj7vVmcOGFlS2TiEgda843kGcXeLY9ZkzXlENEpEE0ZzD44x/zr9ezABGRNM0ZDJ55prh06mtIRARo1mAgIiIlae1goOoiERGgVYOBqodERNK0ZjDQHYGISJrWDAYJukMQEQFaPRiIiAigYCAiIigYVF/md5RFROpQ3F5LpZCnnoK//73WpRARyav1gsGOO3ZtfkOHhkFEpI61VjXRPfeEr5qJiEia1goGY8dC//61LoWISN1prWCQoJfORETStFYwyHzJTC+diYgArRYMREQkq1jBwMwGmtlCM1sZjQfkSPepmT0WDQvi5FlRqi4SEQHi3xnMAha7+2hgcTSfzYfuPj4aDo6ZZ/kS1UKqHhIRSRM3GEwH5kXT84BDYu6va+iOQEQkTdxgMMzdVwNE41xvV/Uxs3Yze8jMcgYMM5sZpWvv6OiIWbQsumUcru4QRESAIt5ANrNFwPAsq2aXkM/W7v6amY0C7jOz5e7+fGYid58LzAVoa2ur7OX7+efD8GyHISIiBYOBu0/Jtc7M1pjZCHdfbWYjgLU59vFaNH7BzB4AdgQ6BYOqOu20Ls1ORKSRxK0mWgDMiKZnAPMzE5jZADPrHU0PBnYFno6ZbzxDhoTxoEE1LYaISL2I21HdHOBmMzsBeAk4HMDM2oB/d/cTgW2BK8xsAyH4zHH3rg0Gkyenz590EvTtC8ce26XFEBGpV+Z12rKmra3N29vby9s488HwX//a9b2ViojUgJktdfe2UrdrjTeQx42rdQlEROpa8weDq6+Gnj1rXQoRkbrW/MFAREQKUjAQEZEWCAZ6y1hEpKDmDwYiIlKQgoGIiCgYiIiIgoGIiNAKwaBH3B43RESaX/MHg2nTal0CEZG61/zBIPODNiIi0knznyn79Kl1CURE6l7zB4NNNql1CURE6l7zBwMRESlIwUBERBQMREQkZjAws4FmttDMVkbjATnSbW1m95rZM2b2tJmNjJOviIhUVtw7g1nAYncfDSyO5rO5DrjA3bcFJgFrY+YrIiIVFDcYTAfmRdPzgEMyE5jZWKCHuy8EcPf33P2DmPmKiEgFxQ0Gw9x9NUA0HpolzRjgLTP7rZktM7MLzKx7zHxFRKSCCnbcY2aLgOFZVs0uIY/dgR2Bl4DfAMcBV2fJayYwE2DrrbcucvciIhJXwWDg7lNyrTOzNWY2wt1Xm9kIsj8LeAVY5u4vRNv8DtiZLMHA3ecCcwHa2tq8uEMQEZG44lYTLQBmRNMzgPlZ0jwKDDCzIdH8PsDTMfMVEZEKihsM5gBTzWwlMDWax8zazOwqAHf/FPgusNjMlgMGXBkzXxERqaBYnf27++vAvlmWtwMnpswvBHaIk1cJZeKcPeCYJ2Dkr+7siixFRBpe072B/OJbL3LWPjD1a0B3NVoSESlG0wWD1z98HYBVg2pcEBGRBtJ0weCDT/Q+m4hIqZouGIiISOmaLhi8/dHbtS6CiEjDabpgsME3JGfMalcQEZEG0nTBQEREStd0wcBRLxYiIqVqumAgIiKla7pgYOg5gYhIqZovGKQ+NNYDZBGRojRdMBi0kV49FhEpVdMFg27WdIckIlJ1TXfm9A/er3URREQaTtMFg+6frK91EUREGk7TBYOevTdOzugBsohIUZouGHivnrUugohIw2m6YEAPBfMcf4IAAAexSURBVAMRkVLFCgZmNtDMFprZymg8IEuavc3ssZThIzM7JE6+BQpVtV2LiDSruHcGs4DF7j4aWBzNp3H3+919vLuPB/YBPgDujZlvTml9EykwiIgUJW4wmA7Mi6bnAYWu+A8Dfu/u+hyZiEgdiRsMhrn7aoBoPLRA+iOBX+daaWYzzazdzNo7OjrKKlD/3v0B6L6hQEIREfmnHoUSmNkiYHiWVbNLycjMRgDbA/fkSuPuc4G5AG1tbWX1Rd2rey8AtninnK1FRFpTwWDg7lNyrTOzNWY2wt1XRyf7tXl29RXgdnf/pIxyiohIFcWtJloAzIimZwDz86T9KnmqiCqlZ/fQtHT4e+gBsohIkeIGgznAVDNbCUyN5jGzNjO7KpHIzEYCWwF/iJlfQZtvsjnzbocFVQ87IiLNo2A1UT7u/jqwb5bl7cCJKfMvAlvEyasUxz7eVTmJiDSH5nsDWURESqZgICIiTRoMJk8OYz1AFhEpSnMGgz59al0CEZGG0pzBQERESqJgICIiTRoMvKyeLEREWlZzBoMEPUAWESlKcwcDEREpioKBiIg0aTDYaKMw7tachyciUmmx+iaqW9dcAz/7Gey+e61LIiLSEJozGAwfDmefXetSiIg0DNWjiIiIgoGIiCgYiIgICgYiIoKCgYiIEDMYmNlAM1toZiuj8YAc6c43s6fM7Bkzu8xM/USIiNSTuHcGs4DF7j4aWBzNpzGzXYBdgR2AccBOwJ4x8xURkQqKGwymA/Oi6XnAIVnSONAH6AX0BnoCa2LmKyIiFRT3pbNh7r4awN1Xm9nQzATuvsTM7gdWAwb8zN2fybYzM5sJzIxm3zOzFTHKNhhYF2P7RtRqx9xqxws65lYR55g/U85GBYOBmS0ChmdZNbuYDMxsG2BbYMto0UIz28PdH8xM6+5zgbnF7LeIfNvdva0S+2oUrXbMrXa8oGNuFbU45oLBwN2n5FpnZmvMbER0VzACWJsl2ZeAh9z9vWib3wM7A52CgYiI1EbcZwYLgBnR9AxgfpY0LwF7mlkPM+tJeHictZpIRERqI24wmANMNbOVwNRoHjNrM7OrojS3As8Dy4HHgcfd/Y6Y+RajItVNDabVjrnVjhd0zK2iy4/ZXN8LFhFpeXoDWUREFAxERKQJg4GZ7W9mK8xslZl1eiO6XpjZNWa21syeTFmWtXsPCy6LjukJM5uQss2MKP1KM5uRsnyimS2PtvlnFyDl5FGh493KzO6PuiR5ysy+2QLH3MfMHjGzx6Nj/n/R8s+a2cNReX5jZr2i5b2j+VXR+pEp+zozWr7CzPZLWZ71915OHhU+9u5mtszM7myFYzazF6Pf3mNm1h4ta6zftrs3zQB0JzysHkV44/lxYGyty5WjrHsAE4AnU5adD8yKpmcB50XTXwR+T3hpb2fg4Wj5QOCFaDwgmh4QrXsEmBxt83vggHLyqODxjgAmRNObAM8BY5v8mA3oF033BB6O8rkZODJa/t/ASdH0ycB/R9NHAr+JpsdGv+XewGej33j3fL/3UvOowu/728CNwJ3llKfRjhl4ERicsayhfts1PylW+B9kMnBPyvyZwJm1Llee8o4kPRisAEZE0yOAFdH0FcBXM9MBXwWuSFl+RbRsBPBsyvJ/pis1jyoe+3xCC7SWOGZgY+CvwL8S3iztkfmbBe4BJkfTPaJ0lvk7TqTL9XuPtikpjwof65aEvsr2Ae4spzwNeMwv0jkYNNRvu9mqibYAXk6ZfyVa1ijSuvcAEt175DqufMtfybK8nDwqLrpN35FwpdzUxxxVlzxGeCFzIeGq9i13X58lz3+WJ1r/NjAoTzlzLR9URh6VdClwOrAhmi+nPI12zA7ca2ZLLXSrAw32247bN1G9ydY1djO0nc11XKUuLyePijKzfsBtwKnu/o7l7s28KY7Z3T8FxpvZZsDthK5ZcuVZ6rFlu5gr9Leo6jGb2YHAWndfamZ7FZFnwx9zZFd3f81C/2wLzezZPGnr8rfdbHcGrwBbpcxvCbxWo7KUY42Fbj2w9O49ch1XvuVbZlleTh4VY+EN9NuAG9z9t2WWp6GOOcHd3wIeINTfbmZmiQux1Dz/WZ5ofX/gjTzlzLV8XRl5VMquwMFm9iJwE6Gq6NIyytNIx4y7vxaN1xKC/iQa7LfdbMHgUWB01KqgF+Fh0YIal6kUubr3WAAcG7UQ2Bl4O7olvAeYZmYDolYE0wj1pKuBd81s56jVwbEZ+yolj4qIynE18Iy7X9wixzwkuiPAzDYCphC6YrkfOCxHeRLlPAy4z0OF7wLgyKhVzGeB0YQHill/79E2peZREe5+prtv6e4jo/Lc5+5HN/Mxm1lfM9skMU34TT5Jo/22K/kQpR4GwlP05wh1s7NrXZ485fw1oVvvTwhR/ARCPeZiYGU0HhilNeDnJLv1aEvZz/8BVkXD8SnL26If5PPAz0i+bV5yHhU63t0It6lPAI9Fwxeb/Jh3AJZFx/wk8H+j5aMIJ7ZVwC1A72h5n2h+VbR+VMq+ZkflXEHUkiTf772cPKrwG9+LZGuipj3mKN/Ho+GpRJka7bet7ihERKTpqolERKQMCgYiIqJgICIiCgYiIoKCgYiIoGAgIiIoGIiICPD/AXfdw31vfKnWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(graph_x1, graph_ll1, c = 'red')\n",
    "plt.plot(graph_x2, graph_ll2, c = 'blue')\n",
    "plt.plot(graph_x3, graph_ll3, c = 'green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = open(\"X_dev.txt\",\"r\")\n",
    "\n",
    "x_dev_tweets = []\n",
    "tokenized_x_dev_tweets = []\n",
    "for tweets in x_dev:\n",
    "    x_dev_tweets.append(tweets)\n",
    "    better_tokenize(tweets, tokenized_x_dev_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0, index=range(len(tokenized_x_dev_tweets)), columns = unique_tokens)\n",
    "\n",
    "i = 0\n",
    "for tweet in tokenized_x_dev_tweets:\n",
    "    for word in tweet:\n",
    "        if word in unique_tokens:\n",
    "            df.at[i,word] = df.at[i,word] + 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sparse = df.as_matrix()\n",
    "\n",
    "intercept = np.ones((sparse.shape[0], 1))\n",
    "sparse = np.hstack((sparse, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(sparse, betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7755581668625147\n"
     ]
    }
   ],
   "source": [
    "x = f1_score(dev_tweets_target, predictions, average='binary')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = open(\"X_test.txt\",\"r\")\n",
    "\n",
    "x_test_tweets = []\n",
    "tokenized_x_test_tweets = []\n",
    "for tweets in x_test:\n",
    "    x_test_tweets.append(tweets)\n",
    "    better_tokenize(tweets, tokenized_x_test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0, index=range(len(tokenized_x_test_tweets)), columns = unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for tweet in tokenized_x_test_tweets:\n",
    "    for word in tweet:\n",
    "        if word in unique_tokens:\n",
    "            df.at[i,word] = df.at[i,word] + 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sparse = df.as_matrix()\n",
    "\n",
    "intercept = np.ones((sparse.shape[0], 1))\n",
    "sparse = np.hstack((sparse, intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predict(sparse, betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Id', 'Category'])\n",
    "\n",
    "ids = []\n",
    "i = 0\n",
    "for x in predictions:\n",
    "    ids.append(i)\n",
    "    i+=1\n",
    "    \n",
    "df['Id'] = ids\n",
    "df['Category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/img/Desktop/630/Week2/hw1/outputs-LR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer: [-0.2  2. ]\n",
      "output layer: [ 3.88 16.18  4.04  1.82  7.9 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "one_hot = [0,0,1,0,0]\n",
    "w1 = [[.6,2],[-.9,8],[-.2,2],[.9,1],[.5,4]]\n",
    "w3 = [[.6,2],[-.9,8],[-.2,2],[.9,1],[.5,4]]\n",
    "\n",
    "h = np.dot(one_hot,w1)\n",
    "print(\"hidden layer: \" + str(h))\n",
    "\n",
    "v = np.dot(w3,h)\n",
    "print(\"output layer: \"+ str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.88, 16.18,  4.04,  1.82,  7.9 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "# np.dot(beta_vector, input_vector)\n",
    "\n",
    "v_prime_j = v[2]\n",
    "v_prime_j_t = np.transpose(v[2])\n",
    "\n",
    "sig = sigmoid(np.dot(v_prime_j_t,h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v_prime_j = v_prime_j - .05*(sig - 1)*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.03308317, 4.04003096])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v_prime_j # new_v_prime_j is our new value of w2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6, 2], [-0.9, 8], [-0.2, 2], [0.9, 1], [0.5, 4]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = sigmoid(np.dot(v_prime_j_t,h))\n",
    "\n",
    "v_i_new = h - .05*(sigmoid(sig-1))*v_prime_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26739907,  1.89901563])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_i_new\n",
    "# vi new is now our updated version of w1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = [0,0,1,0,0]\n",
    "context = [[0,1,0,0,0],[0,0,0,1,0]]\n",
    "negatives = [[1,0,0,0,0],[0,0,0,0,1]]\n",
    "\n",
    "w1 = np.random.uniform(-.5, .5, size=(5, 2))\n",
    "w2 = np.random.uniform(-.5, .5, size=(5, 2))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1253766  -0.43844393]\n"
     ]
    }
   ],
   "source": [
    "hidden = np.dot(one_hot, w1)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10637021, -0.01977895, -0.08702583, -0.11773726, -0.10651646])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.dot(hidden, np.transpose(w2))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding of the input word in w1\n",
    "v_i = w1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding of the input word in w2\n",
    "v_j = w2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the perform descent function should start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the nll here\n",
    "# v_c* in this equation is the embedding of the context word in the W' matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00647374, -0.00606112])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make update with the first context word and first negative sample \n",
    "lr = .05\n",
    "\n",
    "# Positive\n",
    "\n",
    "dot_product_for_sigmoid = np.dot(np.transpose(v_i), hidden)\n",
    "\n",
    "v_j = v_j - lr * (sigmoid(dot_product_for_sigmoid)-1)*hidden\n",
    "v_j\n",
    "\n",
    "summation = lr * (sigmoid(dot_product_for_sigmoid)-1) * v_j\n",
    "\n",
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28587289  0.28097603]\n"
     ]
    }
   ],
   "source": [
    "# Negative\n",
    "\n",
    "dot_product_for_sigmoid = np.dot(np.transpose(v_j), hidden)\n",
    "\n",
    "v_j = v_j - lr * (sigmoid(dot_product_for_sigmoid)-0)*hidden\n",
    "print(v_j)\n",
    "\n",
    "summation = summation + (lr * (sigmoid(dot_product_for_sigmoid)-0) * v_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00037892,  0.00067416])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12535766, -0.43847764])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_i = v_i - lr * summation\n",
    "v_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.uniform(-.5, .5, size=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01218864,  0.11239536],\n",
       "       [-0.33058633, -0.18394748],\n",
       "       [ 0.376982  ,  0.1986052 ],\n",
       "       [ 0.23166047, -0.34558651],\n",
       "       [ 0.00520592, -0.25458162]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.376982 , 0.1986052])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generateSamples(1083, 2))\n",
    "# gives us two random samples that aren't the same as 1083, THE INPUT OF THIS SHOULD BE A ONE HOT ENCODING\n",
    "\n",
    "# print(cumulative_dict[9586544])\n",
    "# gives us a one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have one context word and two negative examples as inputs for this function \n",
    "# The ending resulf from this function will return to us negative log liklihood, but it will also update the weights\n",
    "# of our beta vectors -- we will call the generate samples function within this function \n",
    "\n",
    "# (num_samples, learning_rate, center_token, context_words, W1, W2, negative_indices, index_of_w_matricies)\n",
    "# cumulative_dict[9586544] will get us the one hot index of the sample words\n",
    "\n",
    "# one_hot_of_context_word = mapped_sequence[context_index]\n",
    "# one_hot_negative_sample1 = cumulative_dict[negative_indices[0]]\n",
    "# one_hot_negative_sample2 = cumulative_dict[negative_indices[1]]\n",
    "# # center_token is one hot of center token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.uniform(-.5, .5, size=(5, 2))\n",
    "w2 = np.random.uniform(-.5, .5, size=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performDescent(target_W2_index, hidden, lr, W1, W2, context_W2_index, neg1_context_W2_index, neg2_context_W2_index):\n",
    "\n",
    "\t# (target_W2_index, hidden, lr, W1, W2, context word index from W2(context_W2_index), neg1_context_W2_index, neg2_context_W2_index, )\n",
    "\tnll_new = 0\n",
    "\n",
    "\tv_j = W2[context_W2_index]\n",
    "\tsummation = lr * (sigmoid(np.dot(np.transpose(v_j), hidden))-1) * v_j\n",
    "\tv_j = v_j - lr * (sigmoid(np.dot(np.transpose(v_j), hidden))-1) * hidden\n",
    "\tW2[context_W2_index] = v_j\n",
    "\n",
    "\tv_j = W2[context_W2_index]\n",
    "\tsummation = summation + (lr * sigmoid(np.dot(np.transpose(v_j), hidden))-0) * v_j\n",
    "\tv_j = v_j - lr * (sigmoid(np.dot(np.transpose(v_j), hidden))-0) * hidden\n",
    "\tW2[context_W2_index] = v_j\n",
    "\n",
    "\tv_j = W2[context_W2_index]\n",
    "\tsummation = summation + (lr * sigmoid(np.dot(np.transpose(v_j), hidden))-0) * v_j\n",
    "\tv_j = v_j - lr * (sigmoid(np.dot(np.transpose(v_j), hidden))-0) * hidden\n",
    "\tW2[context_W2_index] = v_j\n",
    "\n",
    "\tv_i = W1[context_W2_index]\n",
    "\tv_i = v_i - lr * summation\n",
    "\tW1[context_W2_index] = v_i\n",
    "\n",
    "\t\t#... (TASK) implement gradient descent. Find the current context token from context_words\n",
    "\t\t#... and the associated negative samples from negative_indices. Run gradient descent on both\n",
    "\t\t#... weight matrices W1 and W2.\n",
    "\t\t#... compute the total negative log-likelihood and store this in nll_new.\n",
    "\t\t#... You don't have to use all the input list above, feel free to change them\n",
    "\tE = -(math.log(sigmoid(np.dot(W2[context_W2_index], hidden))))\n",
    "\t# E_neg1 = (math.log(sigmoid(np.dot(W2[neg1_context_W2_index], hidden))))\n",
    "\t# E_neg2 = (math.log(sigmoid(np.dot(W2[neg2_context_W2_index], hidden))))\n",
    "\tE_neg = (math.log(sigmoid(np.dot(W2[neg1_context_W2_index], hidden)))) + (math.log(sigmoid(np.dot(W2[neg2_context_W2_index], hidden))))\n",
    "\tnll_new = E - E_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performDescent(2, hidden, .05, W1, W2, context_W2_index, neg1_context_W2_index, neg2_context_W2_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
